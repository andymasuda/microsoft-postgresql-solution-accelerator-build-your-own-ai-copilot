# 4.1 Extract Data with Document Intelligence

TODO: Add brief intro to the below topics

## Building an AI enhanced Data Ingestion and Processing Pipeline

To build an AI-powered application that elevates data analysis with generative AI capabilities, we will utilize a comprehensive end-to-end solution pipeline. This pipeline begins with documents uploaded to Azure Blob Storage and utilizes Azure services for intelligent data ingestion, automated validation, semantic analysis, and optimized storage. By integrating AI-driven tools like Azure Document Intelligence and Azure AI services, the pipeline delivers reliable, accurate, and scalable data processing. Below is a detailed breakdown of how this pipeline is structured and enhanced.

---

### 1. Document Upload and Event-Driven Workflow

The pipeline begins with financial documents, such as statement of works, and invoices being uploaded to an **Azure Blob Storage** container. These uploads are performed via the existing application and written to existing blob storage, providing the starting point for the automated processing workflow.

- **Azure Blob Storage**: Cost-effective storage solution for incoming documents. It serves as the foundation for real-time and batch data ingestion.
- **Azure Event Grid**: Detects document upload events and triggers downstream processing steps, ensuring an event-driven architecture for real-time responsiveness and minimal latency.

This event-driven design ensures that documents are immediately processed upon arrival, eliminating delays and manual intervention. The event grid performs an HTTP POST request to a webhook hosted in the API which executes python code. The codelogic retrieves the document from Blob Storage and passes the document to **Azure Document Intelligence** (formerly Form Recognizer) for further processing.

---

### 2. AI-Enhanced Data Ingestion and Validation

The pipeline leverages **Azure Document Intelligence** and Azure AI services for automated extraction and validation. This step not only extracts text but also applies AI-driven validation to ensure the accuracy and reliability of the data.

- **Automated Text Extraction**: Azure Document Intelligence extracts structured and unstructured data from financial documents using pre-trained and custom models tailored for financial services.
  - Example: Extracting fields such as account numbers, transaction amounts, customer details, and regulatory clauses.

- **AI-Driven Data Validation**: Azure AI services validate the extracted data by cross-referencing it against predefined rules, business logic, and external datasets (e.g., regulatory guidelines or internal policies).
  - Example: Ensuring that financial transactions match expected formats and compliance requirements.
  - **Benefits**: Minimizes errors, increases accuracy, and ensures compliance with industry standards.

- **Semantic Chunking**: Large documents are broken into smaller, meaningful segments (semantic chunks) for downstream processing and efficient storage.

This AI-enhanced ingestion ensures that only high-quality, validated data progresses through the pipeline.

---

### 3. Intelligent Data Storage in Azure Database for PostgreSQL

The structured and validated text data is stored in an **Azure Database for PostgreSQL** instance. This database serves as the centralized repository for all processed financial documents, enabling efficient storage, querying, and integration with AI models.

- **Data Organization**:
  - Each document is stored as individual rows in the database, with columns for metadata (e.g., document ID, timestamp) and semantic chunks of text.
  
- **Scalability and Performance**: Azure Database for PostgreSQL is optimized for high-performance queries and supports workloads that involve large volumes of data, such as financial institutions managing millions of documents.

---

### 4. Generating Vector Embeddings with Azure AI Extension

To enable advanced AI functionalities, such as semantic search and ranking, the pipeline integrates the **Azure AI extension** for PostgreSQL. This extension allows embeddings to be generated directly within the database using **Azure OpenAI**.

- **Embedding Storage**:
  - A new column is added to the database to store high-dimensional vector embeddings of the document text:

    ```sql
    ALTER TABLE invoices ADD COLUMN embeddings VECTOR(3072);
    ```

- **Embedding Generation**:
  - Azure OpenAI generates embeddings for the text chunks, enabling semantic understanding and efficient similarity searches. The process is seamless and happens directly in the database.

- **Applications**:
  - These embeddings enable capabilities like semantic search, ranking, and document clustering, enhancing downstream workflows for analytics and intelligent responses.

---

### Benefits of the Enhanced Pipeline

By incorporating **AI-driven validation** and seamless integration of **Azure Document Intelligence** and **Azure OpenAI**, this pipeline delivers:

- **High-Quality Data**: Ensures the reliability and accuracy of financial data through automated validation.
- **Scalability**: Handles large volumes of financial documents with real-time responsiveness.
- **Semantic Understanding**: Enables advanced AI capabilities like vector search and semantic ranking, paving the way for intelligent financial applications.
- **End-to-End Automation**: Reduces manual intervention, streamlines workflows, and ensures consistent processing.

This robust pipeline architecture transforms financial data into actionable insights, setting the stage for advanced analytics and intelligent copilot applications in the financial services industry.



## Build and train custom extraction models

TODO

https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/build-a-custom-model?view=doc-intel-4.0.0
